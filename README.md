# ğŸ§© Agente LangGraph + RAG

Asistente conversacional en Python que combina:

| Componente | TecnologÃ­as |
|------------|-------------|
| **OrquestaciÃ³n** | [LangGraph](https://github.com/langchain-ai/langgraph) |
| **Razonamiento LLM** | OpenAI GPT-4 (mini) vÃ­a `langchain_openai` |
| **Memoria de conocimiento** | RAG local con [FAISS](https://github.com/facebookresearch/faiss) |
| **Herramientas** | `Herramienta_RAG` (bÃºsqueda semÃ¡ntica)<br>FÃ¡cil de extender con mÃ¡s tools |

> El CLI principal es **`chat_agente.py`**.  
> Los notebooks `prueba.ipynb` y `agente.ipynb` se usan solo para pruebas / exploraciÃ³n.

---

## ğŸ“‚ Estructura rÃ¡pida
```bash
â”œâ”€ chat_agente.py # <â€” script interactivo que usarÃ¡s en producciÃ³n
â”œâ”€ src/
â”‚ â”œâ”€ components/
â”‚ â”‚ â”œâ”€ assistant.py
â”‚ â”‚ â”œâ”€ estado.py
â”‚ â”‚ â””â”€ utils.py
â”‚ â”œâ”€ config/
â”‚ â”‚ â”œâ”€ config.py
â”‚ â”‚ â””â”€ prompt.py
â”‚ â””â”€ tools/
â”‚ â”œâ”€ Herramienta_RAG.py
â”‚ â””â”€ rag.py
â”œâ”€ data/ # corpus local; se crea Ã­ndice FAISS aquÃ­
â”œâ”€ prueba.ipynb # notebook: carga corpus y genera Ã­ndice
â””â”€ agente.ipynb # notebook: ejemplo de flujo LangGraph
```


---

## ğŸš€ InstalaciÃ³n

```bash
# 1. Clona el repo
git clone https://github.com/tu-usuario/tu-repo.git
cd tu-repo

# 2. Entorno virtual (opcional pero recomendado)
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# 3. Dependencias
pip install -r requirements.txt
# o, si usas Poetry / pip-tools, adapta este paso


Variables de entorno
Crea un archivo .env en la raÃ­z (o exports en tu shell):
OPENAI_API_KEY=sk-...
# Opcional: LANGCHAIN_TRACING_V2=true  (si usas LangSmith)
```

## ğŸ—‚ï¸ Construir el Ã­ndice RAG
Coloca tus PDFs / TXTs en la carpeta data/.

Abre el notebook prueba.ipynb y ejecuta las celdas:
esto lee los documentos, los parte en chunks, calcula embeddings y guarda:

data/index.faiss â€“ vectores

data/metadata.jsonl â€“ texto + metadatos

âš ï¸ Se usa CPU FAISS por defecto.
Si tienes CUDA, instala faiss-gpu y el script lo aprovecharÃ¡ automÃ¡ticamente.


## ğŸ’¬ Chatear con tu agente

```bash
python chat_agente.py
```
Escribe tu pregunta y pulsa Enter.

El agente consultarÃ¡ su RAG + GPT-4 y responderÃ¡.

Teclea exit o quit para salir.



## âš™ï¸ PersonalizaciÃ³n rÃ¡pida

| QuÃ© quieres cambiar |	DÃ³nde | 
|------------|-------------|
| Modelo (p. ej. gpt-4o-2024-08-06) |	src/config/config.py â†’ get_chat_model() | 
| Prompt, idioma, tono | src/config/prompt.py (funciÃ³n build_prompt si la activas) | 
| AÃ±adir herramienta (requests, calculadora, etc.) | Crea un .py en src/tools/ y aÃ±Ã¡delo a la lista tools = [...] en chat_agente.py | 
| TamaÃ±o del Ã­ndice RAG | Ajusta el chunking / batch embeddings en src/tools/rag.py | 



## ğŸ› ï¸ SoluciÃ³n de problemas
Mensaje	Causa & remedio
â€œFaiss GPU â€¦ not definedâ€ ->	Aviso de que no tienes FAISS-GPU; ignÃ³ralo si usas CPU.
OPENAI_API_KEY not set  ->		Crea .env o exporta la variable en tu shell.
Se repite el texto del usuario	 ->	 AsegÃºrate de usar el Ãºltimo bloque for ev in agente.stream() dentro de chat_agente.py.
Consume demasiados tokens ->		Reduce max_tokens en get_chat_model() o recorta state["messages"] a los Ãºltimos n turnos.



## ğŸ“ Licencia
Este proyecto se distribuye bajo la licencia MIT. Consulta el archivo [LICENSE](LICENSE) para mÃ¡s detalles.
