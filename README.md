# ğŸ§© Agente LangGraph + RAG

Asistente conversacional inteligente en Python que combina LangGraph con RAG local para crear un agente conversacional potente y personalizable.

## âœ¨ CaracterÃ­sticas

- ğŸ¤– **Agente conversacional inteligente** con LangGraph
- ğŸ“š **RAG local** con FAISS para bÃºsqueda semÃ¡ntica
- ğŸ› ï¸ **Arquitectura modular** fÃ¡cil de extender
- ğŸ“Š **Sistema de logging** profesional con archivos de log
- ğŸ”„ **Re-intentos automÃ¡ticos** con manejo de errores robusto
- ğŸ¨ **Respuestas poÃ©ticas** en espaÃ±ol
- ğŸ“„ **Procesamiento de documentos** (PDF, DOCX, TXT)
- ğŸ§µ **Thread IDs dinÃ¡micos** para gestiÃ³n de sesiones
- ğŸ¯ **BÃºsqueda semÃ¡ntica** avanzada en documentos
- âš¡ **Performance optimizada** con batching de embeddings

## ğŸ—ï¸ Arquitectura

| Componente | TecnologÃ­as |
|------------|-------------|
| **OrquestaciÃ³n** | [LangGraph](https://github.com/langchain-ai/langgraph) |
| **Razonamiento LLM** | OpenAI GPT-4 (mini) vÃ­a `langchain_openai` |
| **Memoria de conocimiento** | RAG local con [FAISS](https://github.com/facebookresearch/faiss) |
| **Herramientas** | `Herramienta_RAG` (bÃºsqueda semÃ¡ntica)<br>FÃ¡cil de extender con mÃ¡s tools |
| **Logging** | Sistema centralizado con archivos timestamped |
| **ConfiguraciÃ³n** | Variables de entorno + archivos de configuraciÃ³n |

> **ğŸ’¡ El CLI principal es `chat_agente.py`**  
> Los notebooks `prueba.ipynb` y `agente.ipynb` se usan solo para pruebas / exploraciÃ³n.

---

## ğŸ“‚ Estructura del Proyecto

```
mi_agente/
â”œâ”€â”€ chat_agente.py              # ğŸš€ Script principal para usar en producciÃ³n
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ agent_builder.py    # ğŸ”§ Constructor del agente
â”‚   â”‚   â”œâ”€â”€ assistant.py        # ğŸ¤– Wrapper del LLM con retry logic
â”‚   â”‚   â”œâ”€â”€ estado.py           # ğŸ“Š DefiniciÃ³n del estado LangGraph
â”‚   â”‚   â””â”€â”€ utils.py            # ğŸ› ï¸ Utilidades del agente
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ config.py           # âš™ï¸ ConfiguraciÃ³n del modelo
â”‚   â”‚   â”œâ”€â”€ logging_config.py   # ğŸ“ Sistema de logging centralizado
â”‚   â”‚   â””â”€â”€ prompt.py           # ğŸ’¬ Prompts del sistema
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ Herramienta_RAG.py  # ğŸ” Herramienta de bÃºsqueda semÃ¡ntica
â”‚       â”œâ”€â”€ rag.py              # ğŸ“š ImplementaciÃ³n RAG local
â”‚       â””â”€â”€ rag_promp.py        # ğŸ“ Prompts para RAG
â”œâ”€â”€ data/                       # ğŸ“ Documentos y Ã­ndices FAISS
â”‚   â”œâ”€â”€ faiss_indexes/          # ğŸ” Ãndices vectoriales
â”‚   â””â”€â”€ *.pdf, *.txt, *.docx    # ğŸ“„ Documentos para procesar
â”œâ”€â”€ logs/                       # ğŸ“Š Archivos de log timestamped
â”œâ”€â”€ requirements.txt            # ğŸ“¦ Dependencias del proyecto
â”œâ”€â”€ README.md                   # ğŸ“– Este archivo
â”œâ”€â”€ prueba.ipynb               # ğŸ§ª Notebook para crear Ã­ndices RAG
â””â”€â”€ agente.ipynb               # ğŸ”¬ Notebook de experimentaciÃ³n
```

---

## ğŸ“‹ Requisitos del Sistema

- **Python**: 3.9 o superior
- **Memoria RAM**: MÃ­nimo 4GB (recomendado 8GB+)
- **Espacio en disco**: 1GB para dependencias + espacio para documentos
- **API Key**: OpenAI API key vÃ¡lida
- **Sistema operativo**: Windows, macOS, Linux

---

## ğŸš€ InstalaciÃ³n RÃ¡pida

### 1. Clonar y Preparar
```bash
# Clona el repositorio
git clone https://github.com/tu-usuario/mi_agente.git
cd mi_agente

# Crear entorno virtual (recomendado)
python -m venv .venv

# Activar entorno virtual
# Windows:
.venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate
```

### 2. Instalar Dependencias
```bash
# Instalar todas las dependencias
pip install -r requirements.txt
```

### 3. Configurar Variables de Entorno
Crea un archivo `.env` en la raÃ­z del proyecto:

```bash
# Variables obligatorias
OPENAI_API_KEY=sk-your-openai-api-key-here

# Variables opcionales
MODEL_NAME=gpt-4o-mini
MODEL_TEMPERATURE=0
MODEL_MAX_TOKENS=1024
LOG_LEVEL=INFO
RAG_CHUNK_SIZE=1000
RAG_OVERLAP=25
```

---

## ğŸ—‚ï¸ Preparar el Ãndice RAG

### 1. AÃ±adir Documentos
Coloca tus documentos en la carpeta `data/`:
- **PDFs**: `.pdf`
- **Documentos Word**: `.docx`
- **Archivos de texto**: `.txt`

### 2. Crear el Ãndice
```bash
# OpciÃ³n A: Usar el notebook
jupyter lab prueba.ipynb

# OpciÃ³n B: Usar Python directamente
python -c "
from src.tools.rag import RAG
rag = RAG()
rag.create_index('data/')
print('âœ… Ãndice RAG creado exitosamente')
"
```

El proceso crearÃ¡:
- `data/faiss_indexes/vectorized_db.bin` - Vectores FAISS
- `data/faiss_indexes/vectorized_db_meta.txt` - Metadatos

> **âš ï¸ Nota**: Se usa FAISS CPU por defecto. Si tienes CUDA, instala `faiss-gpu` para mejor performance.

---

## ğŸ’¬ Usar el Agente

### Ejecutar el Chat
```bash
python chat_agente.py
```

### Ejemplo de InteracciÃ³n
```
ğŸ’¬  Escribe 'exit' para terminar.

ğŸ‘¤: Â¿QuÃ© son las redes neuronales?
ğŸ¤–: Un cerebro artificial, con conexiones digitales,
    Las redes neuronales son sistemas computacionales
    Que imitan el funcionamiento del cerebro humano.
    
    Son como una red de neuronas interconectadas,
    Cada una procesando informaciÃ³n y pasÃ¡ndola
    A sus vecinas, creando patrones de aprendizaje
    Que permiten resolver problemas complejos.

ğŸ‘¤: Â¿CÃ³mo funciona el deep learning?
ğŸ¤–: Capas de aprendizaje, cada vez mÃ¡s profundas,
    El deep learning usa mÃºltiples capas neuronales
    Para extraer caracterÃ­sticas cada vez mÃ¡s abstractas.
    
    Es como un artista que pinta en capas:
    Primero los trazos bÃ¡sicos, luego los detalles,
    Y finalmente la obra maestra emerge
    De la combinaciÃ³n de todas las capas.

ğŸ‘¤: exit
ğŸ‘‹ Â¡Hasta luego!
```

---

## âš™ï¸ PersonalizaciÃ³n

### Cambios RÃ¡pidos

| QuÃ© cambiar | DÃ³nde | Ejemplo |
|-------------|-------|---------|
| **Modelo LLM** | `src/config/config.py` â†’ `get_chat_model()` | `gpt-4o-2024-08-06` |
| **Prompt del sistema** | `src/config/prompt.py` | Cambiar tono, idioma, comportamiento |
| **Nuevas herramientas** | `src/tools/` + `src/components/agent_builder.py` | Calculadora, web search, etc. |
| **ConfiguraciÃ³n RAG** | `src/tools/rag.py` | `chunk_size`, `overlap` |
| **Nivel de logging** | Variable `LOG_LEVEL` | `DEBUG`, `INFO`, `WARNING` |

### ConfiguraciÃ³n Avanzada

#### Variables de Entorno Disponibles
```bash
# Obligatorio
OPENAI_API_KEY=sk-your-key-here

# Modelo y parÃ¡metros
MODEL_NAME=gpt-4o-mini
MODEL_TEMPERATURE=0
MODEL_MAX_TOKENS=1024

# Logging
LOG_LEVEL=INFO
LOG_TO_FILE=true

# RAG
RAG_CHUNK_SIZE=1000
RAG_OVERLAP=25
RAG_EMBEDDING_MODEL=text-embedding-3-large

# LangSmith (opcional)
LANGCHAIN_TRACING_V2=false
LANGSMITH_API_KEY=your-langsmith-key
LANGSMITH_PROJECT=mi_agente
```

#### Niveles de Logging
- `DEBUG`: InformaciÃ³n detallada para desarrollo
- `INFO`: InformaciÃ³n general (por defecto)
- `WARNING`: Solo advertencias y errores
- `ERROR`: Solo errores crÃ­ticos

---

## ğŸ”§ Desarrollo

### AÃ±adir Nuevas Herramientas

1. **Crear el archivo de herramienta** en `src/tools/`:
```python
from langchain.tools import tool

@tool
def mi_nueva_herramienta(parametro: str) -> str:
    """DescripciÃ³n de lo que hace la herramienta."""
    # ImplementaciÃ³n aquÃ­
    return resultado
```

2. **AÃ±adir al agente** en `src/components/agent_builder.py`:
```python
from src.tools.mi_nueva_herramienta import mi_nueva_herramienta

tools = [Herramienta_RAG, mi_nueva_herramienta]
```

3. **Documentar** su uso en el README

### Estructura de Desarrollo
```
src/
â”œâ”€â”€ components/     # Componentes del agente
â”œâ”€â”€ config/        # ConfiguraciÃ³n y prompts
â”œâ”€â”€ tools/         # Herramientas disponibles
â””â”€â”€ utils/         # Utilidades comunes
```

### Logs y Debugging
- Los logs se guardan en `logs/mi_agente_YYYYMMDD_HHMMSS.log`
- Usa `LOG_LEVEL=DEBUG` para informaciÃ³n detallada
- Revisa los logs para debugging y monitoreo

---

## ğŸ“Š Monitoreo y MÃ©tricas

### Logs AutomÃ¡ticos
- **Sesiones**: Cada ejecuciÃ³n genera un archivo de log Ãºnico
- **BÃºsquedas RAG**: Se registran todas las consultas semÃ¡nticas
- **Errores**: Captura y registra errores automÃ¡ticamente
- **Performance**: Tiempo de respuesta y uso de tokens

### Archivos de Log
```
logs/
â”œâ”€â”€ mi_agente_20240115_143022.log  # SesiÃ³n especÃ­fica
â”œâ”€â”€ mi_agente_20240115_150145.log  # Otra sesiÃ³n
â””â”€â”€ ...
```

### InformaciÃ³n Registrada
- Timestamp de cada interacciÃ³n
- Consultas RAG realizadas
- Errores y excepciones
- Tiempo de respuesta del LLM
- Uso de tokens

---

## ğŸ› ï¸ SoluciÃ³n de Problemas

### Errores Comunes

| Error | Causa | SoluciÃ³n |
|-------|-------|----------|
| `"Faiss GPU ... not defined"` | No tienes FAISS-GPU instalado | IgnÃ³ralo si usas CPU, o instala `faiss-gpu` |
| `"OPENAI_API_KEY not set"` | Variable de entorno faltante | Crea archivo `.env` con tu API key |
| `"Se repite el texto del usuario"` | Problema en el streaming | AsegÃºrate de usar el Ãºltimo bloque `for ev in agente.stream()` |
| `"Consume demasiados tokens"` | Respuestas muy largas | Reduce `max_tokens` o ajusta el prompt |
| `"No se encuentra el Ã­ndice RAG"` | Ãndice no creado | Ejecuta `prueba.ipynb` para crear el Ã­ndice |
| `"Error de conexiÃ³n a OpenAI"` | Problemas de red/API | Verifica tu conexiÃ³n y API key |

### Debugging Avanzado

1. **Activar logging detallado**:
```bash
export LOG_LEVEL=DEBUG
python chat_agente.py
```

2. **Verificar configuraciÃ³n**:
```python
from src.config.config import get_chat_model
model = get_chat_model()
print(f"Modelo configurado: {model.model_name}")
```

3. **Probar RAG directamente**:
```python
from src.tools.rag import RAG
rag = RAG()
results = rag.query("tu consulta", k=3)
print(results)
```

---

## ğŸ¤ Contribuir

### CÃ³mo Contribuir

1. **Fork** el repositorio
2. **Crea** una rama para tu feature:
   ```bash
   git checkout -b feature/nueva-herramienta
   ```
3. **Commit** tus cambios:
   ```bash
   git commit -am 'AÃ±adir nueva herramienta de bÃºsqueda web'
   ```
4. **Push** a la rama:
   ```bash
   git push origin feature/nueva-herramienta
   ```
5. **Crea** un Pull Request

### EstÃ¡ndares de CÃ³digo

- âœ… Usa **type hints** en todas las funciones
- âœ… AÃ±ade **docstrings** descriptivos
- âœ… Sigue el **formato de logging** establecido
- âœ… Incluye **tests** para nuevas funcionalidades
- âœ… MantÃ©n la **arquitectura modular**
- âœ… Documenta **nuevas herramientas**

### Ãreas de Mejora

- ğŸ” **MÃ¡s herramientas**: Web search, calculadora, etc.
- ğŸ¨ **Interfaz web**: Dashboard para monitoreo
- ğŸ“Š **MÃ©tricas avanzadas**: AnÃ¡lisis de uso y performance
- ğŸ” **AutenticaciÃ³n**: Sistema de usuarios
- ğŸŒ **API REST**: Endpoints para integraciÃ³n

---

## ğŸ“ Licencia

Este proyecto se distribuye bajo la licencia MIT. Consulta el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

## ğŸ™ Agradecimientos

- [LangChain](https://github.com/langchain-ai/langchain) por el framework
- [LangGraph](https://github.com/langchain-ai/langgraph) por la orquestaciÃ³n
- [FAISS](https://github.com/facebookresearch/faiss) por la bÃºsqueda vectorial
- [OpenAI](https://openai.com/) por los modelos de lenguaje

---

**â­ Si este proyecto te es Ãºtil, Â¡dale una estrella en GitHub!**
