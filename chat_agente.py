#!/usr/bin/env python
"""
chat_agente.py  Â·  CLI para conversar con tu agente LangGraph + RAG
-------------------------------------------------------------------
Ejecuta:
    python chat_agente.py
y escribe tu pregunta cuando veas el prompt ğŸ‘¤:
Sal con  exit  o  quit
"""

from __future__ import annotations

import sys
import os
from typing import TypedDict

# ---------- CONFIGURACIÃ“N DE LOGGING ----------
from src.config.logging_config import setup_logging, get_logger
import os
from datetime import datetime

# Crear carpeta de logs si no existe
os.makedirs("logs", exist_ok=True)

# Generar nombre de archivo con timestamp
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
log_filename = f"logs/mi_agente_{timestamp}.log"

# Configurar logging antes de importar otros mÃ³dulos
setup_logging(
    level="DEBUG", #INFO
    log_file=log_filename,
    format_string="%(asctime)s | %(levelname)s | %(name)s | %(message)s"
)
logger = get_logger(__name__)

# ---------- IMPORTS DEL PROYECTO ----------
from src.config.config import get_chat_model
from src.config.prompt import prompt as mi_prompt
from src.components.utils import create_tool_node_with_fallback, route_tools, handle_tool_error, _print_event
from src.components.assistant import Assistant
from src.components.estado import State
from src.tools.Herramienta_RAG import Herramienta_RAG 
from src.tools.rag import init_rag

# ---------- LANGRAPH IMPORTS ----------
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import END, StateGraph, START

# ---------- CONFIGURACIÃ“N ----------
logger.info("Inicializando RAG...")
init_rag("data")
logger.info("Inicializando modelo de chat...")
model = get_chat_model() 

# ConfiguraciÃ³n dinÃ¡mica del thread_id
def get_thread_id() -> str:
    """Genera un ID Ãºnico para la sesiÃ³n actual."""
    import uuid
    return f"session_{uuid.uuid4().hex[:8]}"

config = {
    "configurable": {
        "thread_id": get_thread_id(),
    }
}

# ---------- CONSTRUCTOR DEL AGENTE ----------
def build_agent() -> StateGraph:
    """
    Devuelve un grafo-agente:
    prompt  âœ  LLM  âœ  Assistant (con herramientas)  âœ  END
    """
    try:
        logger.info("Construyendo agente...")
        
        # Define the LLM for the agent
        llm = model

        # Define the system prompt for the agent using a chat prompt template
        prompt = mi_prompt

        # Define the tools that the agent can use
        tools = [Herramienta_RAG]
        logger.debug(f"Herramientas configuradas: {[tool.name for tool in tools]}")

        # Bind the tools to the LLM via the prompt
        assistant_runnable = prompt | llm.bind_tools(tools)

        # Build the state graph for the agent
        builder = StateGraph(State)
        
        # Define Nodes
        builder.add_node("assistant", Assistant(assistant_runnable, max_retries=3))
        builder.add_node("tools", create_tool_node_with_fallback(tools))

        # Define edges
        builder.add_edge(START, "assistant")
        builder.add_conditional_edges(
            "assistant", route_tools, ["tools", END]
        )
        builder.add_edge("tools", "assistant")

        # Set up the memory checkpointer for the graph
        memory = MemorySaver()
        agent_graph = builder.compile(
            checkpointer=memory,
        )
        logger.info("âœ… Agente compilado exitosamente")
        return agent_graph
        
    except Exception as e:
        logger.exception("âŒ Fallo inicializando el agente")
        raise 

# ---------- BUCLE INTERACTIVO ----------
def main() -> None:
    try:
        agente = build_agent()
        state: State = {"messages": []}  
        _printed: set[str] = set()         # evita repetir eventos en _print_event

        print("\nğŸ’¬  Escribe 'exit' para terminar.\n")
        logger.info("ğŸš€ Agente listo para conversar")

        while True:
            try:
                user_text = input("ğŸ‘¤: ").strip()
            except (EOFError, KeyboardInterrupt):
                print("\nğŸ‘‹ Hasta luego!")
                logger.info("SesiÃ³n terminada por el usuario")
                break

            if user_text.lower() in {"exit", "quit"}:
                print("ğŸ‘‹ Hasta luego!")
                logger.info("SesiÃ³n terminada por comando")
                break
            if not user_text:
                continue

            logger.debug(f"Usuario dice: {user_text[:50]}...")
            
            # 1) turno del usuario
            state["messages"].append(("user", user_text))

            # 2) stream del grafo  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            try:
                for ev in agente.stream(state, config, stream_mode="values"):
                    state = ev                      # â† cada 'ev' es el nuevo estado
                logger.debug("Procesamiento del agente completado")
            except Exception as e:
                logger.error(f"Error en el procesamiento del agente: {str(e)}")
                print(f"ğŸ¤–: Lo siento, hubo un error procesando tu pregunta: {str(e)}")
                continue

            # 3) extrae la Ãºltima respuesta del asistente
            asistencia = None
            for msg in reversed(state["messages"]):
                # LangChain guarda HumanMessage / AIMessage; tÃº aÃ±ades tuplas
                if getattr(msg, "type", None) == "ai" or (
                    isinstance(msg, tuple) and msg[0] == "assistant"
                ):
                    asistencia = msg.content if hasattr(msg, "content") else msg[1]
                    break

            if asistencia:
                print(f"ğŸ¤–: {asistencia}\n")
                logger.debug(f"Asistente responde: {asistencia[:100]}...")
            else:
                logger.warning("No se encontrÃ³ respuesta del asistente")
                print("ğŸ¤–: Lo siento, no pude generar una respuesta vÃ¡lida.")

    except Exception as e:
        logger.exception("Error crÃ­tico en la aplicaciÃ³n")
        print(f"âŒ Error crÃ­tico: {str(e)}")
        sys.exit(1)

# ---------- ENTRY POINT ----------
if __name__ == "__main__":
    main()